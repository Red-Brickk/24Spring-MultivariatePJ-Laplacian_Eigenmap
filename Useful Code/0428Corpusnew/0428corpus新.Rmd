---
title: "0420corpus"
author: "Brick"
date: "2024-04-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


本 R markdown 筆記本用於處理corpus數據集。
首先，對此數據做一簡單介紹：
Brown Corpus是著名的英文語料庫，內含若干篇文字材料。建立數據集的步驟如下：
1. 統計出語料庫中出現頻率最高的300個單詞（排除出現次數最多的若干詞），記為T300
2. 對T300中每一個詞，找到其在語料庫中出現的位置（可能出現成百上千次）
3. 從此位置出發，向左和向右各檢查兩個單詞，查看是否有T300中的單詞。
4. 對A,B,C都是T300中的詞，每次在A詞左邊1格或2格的位置見到B詞，就在數據集的第A行，第B列加1；每次在A詞右邊1格或2格的位置見到C詞，就在數據集的第A行，第300+C列的位置加1。


# 引入必要的庫

```{r message=FALSE, warning=FALSE}
# install.packages("Rdimtools")
library(Rdimtools) # 用於實施拉普拉斯特征映射
library(plotly) # 用於交互式繪圖
```


# 檢查數據

```{r}
setwd("D:/Study/Courses/2024Spring/multivariate/Project/code/0420corpus成功")
rawdf <- read.csv("corpus_neighboring_embedding_matrix.csv")
# 表格的第一列是單詞名，故捨去
df <- rawdf[,2:601]
# 將單詞名作為數據框的行名
rownames(df) <- rawdf[,1]
```

## 了解數據集的基本情況

```{r}
# # 出现次数最多的单词对是？
# max(df)
# # 每个单词对平均出现多少次？
# sum(df)/(300*600)
# # 每个单词见证了多少个单词对？
rsum <- apply(df, 1, sum)
# hist(rsum, main="Row Sum (How many word pairs do the 300 words observe)", xlab="row sum")
cat("Row Sum Top 10\n")
sort(rsum,decreasing=T)[1:10]
cat("\nRow Sum Least 10\n")
sort(rsum,decreasing=F)[1:10]
# # 每个单词多少次作为语境词出现？
csum <- apply(df, 2, sum)
# hist(csum, main="Column Sum (How often does a word be a context word)", xlab="column sum")
cat("\nColumn Sum Top 10\n")
sort(csum,decreasing=T)[1:10]
cat("\nColumn Sum Least 10\n")
sort(csum,decreasing=F)[1:10]
```

可認為拉普拉斯特征映射分兩步，一是由原始數據構建圖，二是根據圖找圖函數。數據降維表示的效果是否良好，關鍵在於構建圖。對於第二步，“找最平滑的圖函數”這一任務，已有解析解，我們重在闡釋，無法改進。但對於第一步，需要科學地對比、搜索，以找到最適合具體問題的圖構建方案。

# 找拉普拉斯特征映射

## 定義對比測試函數
```{r}
test <- function(df_mat,ndim,weighted,method,k,epsilon,tt,figmain){
  if (method=="knn"){
    type <- c("knn",k)
  }
  if (method=="enn"){
    type <- c("enn",epsilon)
  }
  if (!weighted){
    tt=1
  }
  
  # 調用函數，對矩陣，先構造圖，再找它的拉普拉斯映射
  le1 <- do.lapeig(df_mat,ndim=ndim, kernelscale=tt,type=type, weighted=weighted)    
  
  # 記錄映射值
  df_le1 <- as.data.frame(le1$Y)
  mapname <- c("map1","map2","map3","map4","map5")
  colnames(df_le1) <- mapname[1:ndim]
  rownames(df_le1) <- rownames(df_mat)
  
  # 拉普拉斯特征映射的主要內容已呈現在上方，下方代碼主要實現聚簇功能
  # Select number of clusters
  clusters <- 7
  set.seed(123)
  # Build model with k clusters: km.out
  km.out <- kmeans(df_le1, centers = clusters, nstart = 1)
  lab <- km.out$cluster
  
  library(dplyr)
  colors <- c("red", "blue", "green", "purple","cyan","lightblue","lightgreen","black")
  names <- c("cluster1","cluster2","cluster3","cluster4","cluster5","cluster6","cluster7") 

  # 创建散点图
  p <- plot_ly(data = df_le1, x = ~map1, y = ~map2, color=colors[lab],name=names[lab],type = 'scatter', mode = 'markers') %>%
  # 添加文本标签
  add_text(text = rownames(df_le1), textposition = 'top', showlegend = FALSE, hoverinfo = 'text', textfont = list(size = 8))  %>%
  layout(title = figmain)
  print(p)
}
```


### 第一組實驗：找k
此處，我們先不引入熱核，邊權只在{0,1}中選。選定觀察dim1 和 dim2，採用knn方法，比較不同k對降維效果的影響。

```{r}
method <- "knn"
weighted <- FALSE
df_mat <- as.matrix(df, nrows=nrow(df))
# 需要時可用循環比較各參數值
for (k in c(1,2,6,10,20,50,100)){
  test(df_mat,weighted, method=method, k=k, ndim=3, figmain=paste("Laplacian Eigen Map, knn, k=",k))
}
```

### 第二組實驗：標準化後找k
此處，我們先不引入熱核，但對原始數據按列標準化，選定觀察dim1 和 dim2，採用knn方法，比較不同k對降維效果的影響。

```{r}
method <- "knn" # 選KNN還是ENN?
weighted <- FALSE
df_mat <- as.matrix(scale(df), nrows=nrow(df)) # 此處做標準化

# 需要時可用循環比較各參數值
for (k in c(2,6,10,20,50,100)){
  test(df_mat,weighted, method=method, k=k, ndim=3, figmain=paste("Laplacian Eigen Map, Scaled, knn, k=",k))
}
```


### 第三組實驗：找tt
此處，我們引入熱核，選定觀察dim1 和 dim2，採用knn方法，選定k=8，比較不同tt對降維效果的影響。

```{r}
method <- "knn" # 選KNN還是ENN?
weighted <- F
k <- 50
df_mat <- as.matrix(df, nrows=nrow(df))

# 需要時可用循環比較各參數值
for (tt in c(6e5,8e5,1e6)){
  test(df_mat,weighted, method=method, k=10, ndim=2, tt=tt, figmain=paste("Laplacian Eigen Map, knn, weighted k=",10," tt=",tt))
  test(df_mat,weighted, method=method, k=100, ndim=2, tt=tt, figmain=paste("Laplacian Eigen Map, knn, weighted k=",50," tt=",tt))
}
```
有一種到了臨界之後炸開的感覺，想是tt作為指數部分的分母，其倍數變化對於指數的大小來說十分重要。

# 第三組實驗續：scale之後找tt
```{r}
method <- "knn" # 選KNN還是ENN?
weighted <- TRUE
k <- 50
df_mat <- as.matrix(scale(df), nrows=nrow(df))

# 需要時可用循環比較各參數值
for (tt in c(500,1000,1500,2000)){
  test(df_mat,weighted, method=method, k=k, ndim=2, tt=tt, figmain=paste("Laplacian Eigen Map, knn, weighted k=",k," tt=",tt))
}
```
所謂熱核，實際上是在考慮的鄰居數目較多時，用於體現遠近之別的一種手段。對於正是要保持局部相鄰關係，略去全局相鄰關係的LE方法來說，此功能略顯雞肋，食之無味，棄之可惜。tt選得過小，則將大多數鄰邊趨於消滅，整個圖被分為若干連通子圖，中間接著遊絲般的聯繫。這將使得倒數第二特征值趨於0，使得第一個dim失去作用。tt選得過大，又與不用熱核的方法無甚差別。這裡也略談enn。enn不談數目，只談絕對距離，就容易產生彼此不相連的連通子圖，對這一點，只要想象iris數據集就可明白了，這是我們不喜歡的。對iris樣子的數據集，不妨拆成兩堆來做。


### 第四組實驗：找dim
此處，我們不引入熱核，採用knn方法，選定k=8，比較數據點在不同維度上的分佈情況。

# 嘗試用kmeans方法對降維結果做聚類
```{r}
# Select number of clusters
k <- 8
ndim <- 4
type <- c("knn",k)
weighted <- F
df_mat <- as.matrix((df), nrows=nrow(df))

# 調用函數，對矩陣，先構造圖，再找它的拉普拉斯映射
le1 <- do.lapeig(df_mat,ndim=ndim,type=type, weighted=weighted)    
# 記錄映射值
df_le1 <- as.data.frame(le1$Y)
mapname <- c("map1","map2","map3","map4","map5")
colnames(df_le1) <- mapname[1:ndim]
rownames(df_le1) <- rownames(df_mat)

cluster <- 7
set.seed(123)
# Build model with k clusters: km.out
km.out <- kmeans(df_le1, centers = cluster, nstart = 20)
lab <- km.out$cluster

```

## 繪圖查看效果
```{r}
library(dplyr)
colors <- c("red", "blue", "green", "purple","cyan","lightblue","lightgreen","black")
labnames <- c("情態動詞","特殊名詞","難分辨","動詞及過去式","代詞","系動詞、介詞","難分辨2")

# 创建散点图
plist <- list()
plist[[1]] <- plot_ly(data = df_le1, x = ~map1, y = ~map2, color=colors[lab], name = labnames[lab],type = 'scatter', mode = 'markers') %>% 
  add_text(text = rownames(df_le1), textposition = 'top', showlegend = FALSE, hoverinfo = 'text', textfont = list( size = 10))  %>%
  layout(title = paste("Laplacian Eigen Map, knn, k=8, dim1 and dim2"))


plist[[2]] <- plot_ly(data = df_le1, x = ~map1, y = ~map3, color=colors[lab], name = labnames[lab],type = 'scatter', mode = 'markers') %>% 
  add_text(text = rownames(df_le1), textposition = 'top', showlegend = FALSE, hoverinfo = 'text', textfont = list( size = 10))  %>%
  layout(title = paste("Laplacian Eigen Map, knn, k=8, dim1 and dim3"))


plist[[3]] <- plot_ly(data = df_le1, x = ~map2, y = ~map3, color=colors[lab],name = labnames[lab],type = 'scatter', mode = 'markers') %>% 
  add_text(text = rownames(df_le1), textposition = 'top', showlegend = FALSE, hoverinfo = 'text', textfont = list( size = 15))  %>%
  layout(title = paste("Laplacian Eigen Map, knn, k=8, dim2 and dim3"))


plist[[4]] <- plot_ly(data = df_le1, x = ~map1, y = ~map4, color=colors[lab],name = labnames[lab],type = 'scatter', mode = 'markers') %>% 
  add_text(text = rownames(df_le1), textposition = 'top', showlegend = FALSE, hoverinfo = 'text', textfont = list(size = 12))  %>%
  layout(title = paste("Laplacian Eigen Map, knn, k=8, dim1 and dim4"))

plist[[5]] <- plot_ly(data = df_le1, x = ~map2, y = ~map4, color=colors[lab],name = labnames[lab],type = 'scatter', mode = 'markers') %>% 
  add_text(text = rownames(df_le1), textposition = 'top', showlegend = FALSE, hoverinfo = 'text', textfont = list( size = 10))  %>%
  layout(title = paste("Laplacian Eigen Map, knn, k=8, dim2 and dim4"))

plist[[6]] <- plot_ly(data = df_le1, x = ~map3, y = ~map4, color=colors[lab],name = labnames[lab],type = 'scatter', mode = 'markers') %>% 
  add_text(text = rownames(df_le1), textposition = 'top', showlegend = FALSE, hoverinfo = 'text', textfont = list(size = 10))  %>%
  layout(title = paste("Laplacian Eigen Map, knn, k=8, dim3 and dim4"))

print(plist[4])
```

# 第六組實驗：enn

```{r}
method <- "enn" # 選KNN還是ENN?
weighted <- F
df_mat <- as.matrix(scale(df), nrows=nrow(df))
df_del <- df[!rownames(df) %in% c("he","that","is","for","it"), ]
df_mat <- as.matrix(scale(df_del), nrows=nrow(df))
  
# 需要時可用循環比較各參數值
for (epsilon in seq(100,120,10)){
  test(df_mat,weighted, method, epsilon=epsilon, ndim=3, figmain=paste("Laplacian Eigen Map, enn, epsion=",epsilon))
}


```

epsilon較大時，可能無法保證preserving locality。epsilon較小時，可能造成連通子圖（非全連通圖）。可以考慮對連通子圖分別作lapeig，但是這兩部分的點的低維表示，彼此無法互通
knn限制連接點的數量，可以控制perserving locality。當k大於簇的大小時，即可實現圖的全連通。

選到能全連通的時候，epsilon已經太大了。在密集區，基本上是邊的全覆蓋。選小一點，又會有兩個小離群點打架。

1. 為什麼不是全連通圖就做不了eigen decomposition。
這是因為，全連通圖的L的0特征值所對特征空間只有1維，而非全連通圖，若有k個連通子圖，其L的0特征值所對特征空間就有k維，這就和do.lapeig的默認設置產生矛盾。

2. 有沒有辦法修正？
找到連通子圖，對它們分別作lapeig。如果子圖內部能夠設置下比較適當的距離值，也好。然而，不同子圖的坐標之間，無法互通。


## 研究軟件包所實現的，究竟是何矩陣的特征分解。

```{r warning=FALSE}
df_mat <- matrix(c(1,0,0,0,0,1,0,0,0,0,1,0,0,0,1,1),nrow=4)
df_mat

# 調用函數，對矩陣，先構造圖，再找它的拉普拉斯映射
le1 <- do.lapeig(df_mat,ndim=3,method=c("knn",3))

# 步驟2：使用k最近鄰計算鄰接矩陣
dataframe_to_adjmat <- function(df, k){
  dist_matrix <- as.matrix(dist(df))  # 歐幾里得距離矩陣
  
  # 偵測每行的k+1個最小值（自身和k個鄰居）
  # 注意：此時所說的“偵測k+1個最小值”，並非指所得圖中每個點有k個鄰居，原因下陳。
  adj_matrix <- apply(dist_matrix, 1, function(row) {
    smallest <- order(row, decreasing = F)[2:(k+1)]
    weights <- rep(0, length(row))
    weights[smallest] <- 1
    weights
  })
  
  # adj_matrix <- (adj_matrix + t(adj_matrix)) / 2  # 確保矩陣是對稱的（無向圖）
  return(adj_matrix)
}

W <- dataframe_to_adjmat(df_mat, 3)
D <- diag(apply(W,2,sum))
L <- D-W

le1$Y%*%diag(le1$eigvals)%*%t(le1$Y)

L

solve(D)%*%L
```
使用我所理解的LE算法，對L和D^-1L都求了特征分解，結果發現與do.lapeig的返回結果不能對上。由此，暫時也說不出來求的是誰的特征分解。



